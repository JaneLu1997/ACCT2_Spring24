<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link href="Documentation.css" rel="stylesheet">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=DM+Sans:opsz@9..40&family=Playfair+Display&display=swap" rel="stylesheet">
    <title>Documentation: Digital Countdown</title>
</head>
<body>
    <header>
        <h1>Documentation: <br> Digital Finger Puppets</h1>
    </header>
    <main>
        <div class="row">
            <p>
                For this interface, I'm thinking about making a randomizing finger puppet generating machine based on ml5js's hand pose and p5js.
            </p>
        </div>

        <div class="row">
            <p>
                To set up the scene, we need to first flip the video also try to match drawn points to the image. 
            </p>
            <img src="imageFixed.png">
        </div>

        <div class="row">
            <p>
                Second, we need to figure out if we can recognize gestures. After brief research, this is often achieved by TensorFlow. The premeter of this assignment is p5.js and ml5.js. However, this should be maneuvered by training the machine to know specific hand gestures based on the position of the points. As we can see, there's always 21 points registered for one hand. We can also check out each finger's data through annotation -> finger, marked in second picture.
            </p>
            <img src="pointLog.png">
            <img src="AnnotationLog.png">
        </div>

        <div class="row">
            <p>
                Now, as we've found out the data we want the machine to learn and modify, I went ahead and followed this video tutorial instructions: 
            </p>
            <iframe width="750" height="500" src="https://www.youtube.com/embed/A2yFBDBq9UY?si=zJX5khbttd1pqIjZ&amp;start=1880" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
        </div>

        <div class="row">
            <p>
                Now we have three mainly involved finger tips tracked and replaced. However all the images stay still and don't alter their angle based on the finger pointing direction. That's the next step but here's how it looks like so far: 
            </p>
            <img src="ToyTracked.png">
        </div>

        <div class="row">
            <p>
                 To make the toys rotate based on finger direction, we find out the middle point of the finger tip and the first knuckles counting down using sub(). Then using heading() we assign the images with the rotation angle. It's a bit wanky but it's working!
            </p>
            <img src="RotatingToy.png">
        </div>


        <h1>FINAL CODE</h1>
        <iframe src="https://editor.p5js.org/jadedpineapple/full/8dXUsCv5i" width="1200" height="500"></iframe>

    </main>
</body>
</html>